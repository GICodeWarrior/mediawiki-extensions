#!/usr/bin/python
#:vim:ts=python:

''' compute editor lifecycle '''

import re
import os
from argparse import ArgumentParser
import numpy as np
from collections import deque
import datetime as dt

__prog__ = os.path.basename(os.path.abspath(__file__))

def estimaterate(edits, step):
    '''
    This function takes the daily edit history of an individual editor, and a
    step parameter; it estimates the daily activity of the editor. It returns
    the daily rates every `step' days.
    '''
    N = len(edits)
    if N % step:
        NN = np.ceil(N / float(step)) * step
        tmp = np.zeros((NN,), dtype=edits.dtype)
        tmp[:N] = edits
        edits = tmp
    return edits.reshape((-1, step)).sum(axis=-1) / float(step)

def itercycles(npzarchive, every, users=None):
    '''
    Iterates over the archive or over given list of users and returns estimated
    activity life cycle (see estimaterate())
    '''
    for uid in (users or npzarchive.files):
        days, edits = npzarchive[uid].T
        days = days - days.min()
        rates = estimaterate(edits, every)
        yield np.c_[days[::every], rates]

def averagecycle(ratesbyday):
    '''
    Computes average cycle with standard errors. Takes in input a dictionary
    returned by groupbydayssince()
    '''
    all_days = sorted(ratesbyday.keys())
    result = deque()
    for d in all_days:
        s = ratesbyday[d]
        sqN = np.sqrt(len(s))
        result.append((d, np.mean(s), np.std(s)/np.sqrt(len(s))))
    return np.asarray(result)

def groupbyday(npzarchive, every, users=None):
    '''
    This function estimates editors' activity rates and groups rate estimates by
    number of days elapsed since editor registration (which corresponds to time = 0)
    '''
    tmp = {}
    for cyclearr in itercycles(npzarchive, every, users):
        for d, r in cyclearr:
            try:
                tmp[d].append(r)
            except KeyError:
                tmp[d] = deque([r])
    return tmp

def lifetimes(npzarchive, users=None):
    '''
    Returns the distribution of account lifetimes over an archive. Can take an
    optional list users ids to restrict the sample to a specific group of
    editors
    '''
    lt = deque()
    for uid in (users or npzarchive.files):
        days, edits = npzarchive[uid].T
        lt.append(days.ptp())
    return np.asarray(lt)

def find_inactives(npzarchive, inactivity, minimum_activity, maximum_activity):
    now = dt.datetime.now().toordinal()
    epoch = dt.datetime(1970,1,1).toordinal()
    unix_now = now - epoch
    inactives = deque()
    for uid in npzarchive.files:
        days, edits = npzarchive[uid].T
        if days.ptp() <= inactivity:
            continue
        unix_last = days[-1]
        if (unix_now - unix_last) > inactivity:
            tot_edits = float(edits.sum())
            tot_days = float(days.ptp() - inactivity)
            activity = tot_edits / tot_days * 365.0
            if minimum_activity < activity and maximum_activity > activity:
                inactives.append(uid)
    return inactives

parser = ArgumentParser(description=__doc__)
parser.add_argument('data_file', metavar='data')
parser.add_argument(metavar='minact', type=int, dest='minimum_activity')
parser.add_argument(metavar='maxact', type=int, dest='maximum_activity')
parser.add_argument('-key')
parser.add_argument('-every', type=int, help='default: %(default)d days',
        default=30, metavar='NUM')
parser.add_argument('-inactivity', type=int, default=180, help='default: '
        '%(default)d days', metavar='NUM')
parser.add_argument('-all', dest='dump_all', action='store_true')


def main(ns):
    if ns.key is None:
        m = re.match('(.*?)\.npz', ns.data_file, re.I)
        if m is not None:
            ns.key = m.groups()[0]
        else:
            print >> sys.stderr, '%s: cannot determine key from file name: %s'\
                    % (__prog__, ns.data_file)
            sys.exit(1)
    if ns.minimum_activity >= ns.maximum_activity:
        print >> sys.stderr, '%s: error: minact >= maxact' % __prog__
        sys.exit(1)

    # load data 
    npzarchive = np.load(ns.data_file)

    if ns.dump_all:
        fn = mkfn('cycles', ns, 'npz')
        values_iter = itercycles(npzarchive, ns.every)
        keys = npzarchive.files
        tmp = dict(zip(keys, list(values_iter)))
        np.savez(fn, **tmp)
        print '%s: output saved to %s' % (__prog__, fn)
    else:
        # compute lifetime distribution
        lt = lifetimes(npzarchive)

        # compute inactive subgroups
        inactive_users = find_inactives(npzarchive, ns.inactivity, ns.minimum_activity,
                ns.maximum_activity)

        ratesbyday = groupbyday(npzarchive, ns.every)
        ratesbyday_inact = groupbyday(npzarchive, ns.every, inactive_users)

        avg_all = averagecycle(ratesbyday)
        avg_inact = averagecycle(ratesbyday_inact)
        
        lens = [ len(npzarchive.files), len(inactive_users) ]

        names = ['lt', 'len', 'all', 'inact' ]
        arrs = [ lt, lens, avg_all, avg_inact ]
        
        for n, a in zip(names, arrs):
            fn = '%s_%s.%s' % (ns.key, n, 'tsv')
            np.savetxt(fn, a)
            print '%s: output saved to %s' % (__prog__, fn)

if __name__ == '__main__':
    ns = parser.parse_args()
    main(ns)
