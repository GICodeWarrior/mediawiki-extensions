#!/usr/bin/python

# In progress proof of concept for distributed parallel bzip2 compression.
# Breaks incoming data stream into blocks, sends them out for separate
# compression on multiple threads.
#
# Currently running bzip2 chunks in local threads, will try moving to
# remotable network daemons distcc-style. It might or might not be worth
# it depending on the overhead of slinging around all the data.
#
# Like pbzip2 the output files will work with the regular 'bzip2' tool
# but may not work with other programs because each chunk is its own
# separate stream. Other tools tend to end at the first stream's end.
# it might be possible to combine the streams in some way, should
# investigate.
#
# Brion Vibber <brion@pobox.com>
# 2006-05-12

# TODO:
# Selectable block size
# Handle remote failures gracefully
# Merge blocks to single, more compatible stream
# Accept file input/output, behavior like bzip2

import bz2
import getopt
import random
import socket
import struct
import sys
import thread
import time

from thread import start_new_thread

import DistBits
from BitWriter import BitWriter
from sigcheck import findBzTrail

class Compressor(object):
	def __init__(self, args):
		self.inputStream = sys.stdin
		self.outputStream = sys.stdout
		
		self.blockSize = 900000 # 900k default blocksize
		self.threads = 1 # Number of local threads to start.
		self.remotes = []
		self.verbosity = 0
		
		self.crc = 0L
		
		self.blocksRead = 0
		self.blocksCompressed = 0
		self.blocksWritten = 0
		self.bytesRead = 0L
		self.bytesWritten = 0L
		
		self.compressors = []
		self.inputQueue = [] # blocks to be compressed
		self.outputQueue = [] # buffers to be written
		
		self.done = False
		self.threadLock = thread.allocate_lock()
		
		self.processArgs(args)
	
	def processArgs(self, args):
		(options, remainder) = getopt.getopt(args, "vp:r:")
		for (opt, val) in options:
			if opt == "-v":
				self.verbosity += 1
			elif opt == "-p":
				self.threads = int(val)
			elif opt == "-r":
				self.remotes.append(self.splitHost(val))
	
	def splitHost(self, val):
		if ":" in val:
			(host, port) = val.split(":")
			return (host, int(port))
		else:
			return (val, 12345)
	
	def debug(self, level, text):
		if self.verbosity >= level:
			sys.stderr.write(text + "\n")
	
	def run(self):
		"""Start up the threads and goooo!"""
		for i in range(0, self.threads):
			self.compressors.append(LocalCompressor())
		for addr in self.remotes:
			self.compressors.append(RemoteCompressor(addr))
		assert len(self.compressors) >= 1
		
		start_new_thread(self.readerThread, ())
		
		for compressor in self.compressors:
			start_new_thread(self.compressorThread, (compressor,))
		
		self.writerThread()
	
	def sleep(self):
		"""Wait a short time when out of data."""
		time.sleep(0.01)
	
	def lock(self):
		self.threadLock.acquire()
		assert self.threadLock.locked()
	
	def unlock(self):
		self.threadLock.release()
	
	def readerThread(self):
		"""Producer thread: run through the file handing out blocks."""
		self.debug(2, "readerThread: starting!")
		block = self.nextBlock()
		while block:
			while not self.ready():
				self.debug(4, "readerThread: full at %d; waiting" % len(self.inputQueue))
				self.sleep()
			
			self.lock()
			self.blocksRead += 1
			self.debug(2, "readerThread: dispatching block %d" % self.blocksRead)
			self.dispatch(block)
			self.unlock()
			
			block = self.nextBlock()
		self.done = True
		self.debug(2, "readerThread: done; read %d blocks" % self.blocksRead)
	
	def nextBlock(self):
		buffer = self.inputStream.read(self.blockSize - 1000) # some headroom for RLE?
		self.bytesRead += len(buffer)
		self.debug(3, "nextBlock: %d" % len(buffer))
		return buffer
	
	def ready(self):
		"""Check if we have some free compressors. No sense filling up RAM."""
		return len(self.inputQueue) < len(self.compressors)
	
	
	# Queue management

	def dispatch(self, block):
		"""Queue a block of data for remote compression."""
		assert self.threadLock.locked()
		buffer = QueuedBuffer(self.blocksRead, block)
		self.inputQueue.append(buffer) # To the compressor threads
		self.outputQueue.append(buffer) # To the writer thread, in order!
	
	def dequeueInput(self):
		"""Fetch the next available block for compression."""
		assert self.threadLock.locked()
		if len(self.inputQueue):
			return self.inputQueue.pop(0)
		else:
			return None
	
	def dequeueOutput(self):
		"""Fetch the next completed block for writing."""
		assert self.threadLock.locked()
		if len(self.outputQueue) and self.outputQueue[0].ready():
			return self.outputQueue.pop(0)
		else:
			return None
	
	
	def writerThread(self):
		"""Consumer thread: as we receive compressed blocks from the
		distributed compressors, write them to the output file.
		Currently only writes blocks in order."""
		self.debug(2, "writerThread: starting")
		startTime = time.time()
		
		self.bitStream = BitWriter(self.outputStream)
		self.writeHeader()
		
		while not (self.done and self.blocksWritten == self.blocksRead):
			self.lock()
			buffer = self.dequeueOutput()
			self.unlock()
			
			if buffer:
				self.debug(4, "writerThread: wtf")
				self.writeBuffer(buffer)
			else:
				self.debug(4, "writerThread: sleeping")
				self.sleep()
		
		self.writeTrailer()
		self.bitStream.flush()
		
		delta = time.time() - startTime
		megabyte = 1024.0 * 1024.0
		rateIn = (float(self.bytesRead) / megabyte) / delta
		rateOut = (float(self.bytesWritten) / megabyte) / delta
		self.debug(1, "Wrote %d blocks in %0.1f seconds (%0.3f MB/s in, %0.3f MB/s out)" % (
			self.blocksWritten, delta, rateIn, rateOut))
	
	def writeBuffer(self, buffer):
		"""Write a buffer to the file. Currently requires that buffers
		be processed in streaming order."""
		output = buffer.output
		self.blocksWritten += 1
		self.bytesWritten += len(output)
		self.debug(2, "writeBuffer: writing block %d (%d blocks, %d bytes)" %
			(buffer.index, self.blocksWritten, self.bytesWritten))
		
		assert buffer.output is not None
		assert buffer.index == self.blocksWritten
		#self.outputStream.write(buffer.output)
		
		(offset, overflow, crc) = findBzTrail(buffer.output)
		self.debug(2, "writeBuffer: block stream crc %08x, offset %d bits" %
			(crc, offset))
		if offset:
			# Block end is not byte-aligned
			self.bitStream.writeBytes(buffer.output[4:-11])
			self.bitStream.writeBits(overflow, offset)
		else:
			# By amazing chance the block is an integral number of bytes
			self.bitStream.writeBytes(buffer.output[4:-10])
		
		# Assuming there's only one output block per input block
		# This had better hold :D
		blockCrc = struct.unpack(">L", buffer.output[10:14])[0]
		self.crc = ((self.crc << 1) & 0xffffffffL | self.crc >> 31) ^ blockCrc
	
	def writeHeader(self):
		self.debug(4, "writing file header")
		# hardcoded 900k blocksize
		self.bitStream.writeBytes("BZh9")
	
	def writeTrailer(self):
		self.debug(4, "writing file trailer, combined CRC %08x" % self.crc)
		# Stream-end magic number:
		self.bitStream.writeBytes("\x17\x72\x45\x38\x50\x90")
		# 32-bit combined CRC
		self.bitStream.writeBytes(struct.pack(">L", self.crc))
	
	def compressorThread(self, compressor):
		"""Worker thread: send a block to a foreign server and receive data."""
		self.debug(3, "compressorThread: Started")
		blocksCompressed = 0
		bytesRead = 0L
		bytesWritten = 0L
		startTime = time.time()
		
		while not (self.done and self.blocksCompressed == self.blocksRead):
			self.lock()
			buffer = self.dequeueInput()
			self.unlock()
			if buffer:
				self.debug(4, "compressorThread: compressing")
				data = compressor.compress(buffer.input)
				
				self.lock()
				buffer.set(data)
				
				self.blocksCompressed += 1
				blocksCompressed += 1
				bytesRead += len(buffer.input)
				bytesWritten += len(buffer.output)
				
				self.debug(4, "compressorThread: compressed %d blocks" % self.blocksCompressed)
				self.unlock()
			else:
				self.debug(4, "compressorThread: no input, sleeping")
				self.sleep()
		compressor.close()
		
		delta = time.time() - startTime
		megabyte = 1024.0 * 1024.0
		rateIn = (float(bytesRead) / megabyte) / delta
		rateOut = (float(bytesWritten) / megabyte) / delta
		self.debug(1, "%s: processed %d blocks in %0.1f seconds (%0.3f MB/s in, %0.3f MB/s out)" % (
			compressor, blocksCompressed, delta, rateIn, rateOut))
	


class QueuedBuffer(object):
	"""Placeholder for received compressed buffer items."""
	
	def __init__(self, index, input):
		"""Initialize an empty placeholder, no data yet."""
		self.index = index
		self.input = input
		self.output = None
	
	def ready(self):
		return self.output is not None
	
	def set(self, data):
		"""Store data and declare that we're ready to be flushed out."""
		assert self.output is None
		assert data is not None
		self.output = data


class LocalCompressor(object):
	"""For initial testing, we just compress locally."""
	
	def algo(self, algo):
		assert algo == "bzip2"
	
	def compress(self, block):
		return bz2.compress(block)
	
	def close(self):
		pass
	
	def __str__(self):
		return "local thread"

class RemoteCompressor(object):
	def __init__(self, address):
		"""Address is a (host, port) tuple."""
		self.address = address
		self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
		self.socket.connect(address)
		self.connection = DistBits.Connection(self.socket)
		self.connection.send("COMP", struct.pack(">l", 1))
		self.connection.send("ALGO", "bzip2")
	
	def compress(self, data):
		self.connection.send("HUGE", data)
		(atom, retdata) = self.connection.receive()
		if atom == "SMAL":
			return retdata
		elif atom == "EROR":
			raise Exception(data)
		else:
			raise Exception("Unknown return atom type")
	
	def close(self):
		self.connection.send("CLOS")
		self.connection.close()
		self.socket.close()
		self.connection = None
	
	def __str__(self):
		return self.address[0] + ":" + str(self.address[1])

if __name__ == "__main__":
	compressor = Compressor(sys.argv[1:])
	compressor.run()
